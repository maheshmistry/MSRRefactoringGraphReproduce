{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules import datasetconfig\n",
    "from modules import util\n",
    "import pandas as pd\n",
    "import re\n",
    "import logging\n",
    "import os.path\n",
    "import networkx as nx\n",
    "from graphviz import Digraph\n",
    "import io\n",
    "\n",
    "#----------------------------  \n",
    "def extract_graph_data_from_csv(language, csv_file_name):\n",
    "  dataset = util.read_csv(csv_file_name)\n",
    "  node_number = 0\n",
    "  edge_number = 0\n",
    "  nodes = {}\n",
    "  edges = {}\n",
    "  dictionary = datasetconfig.get_dictionary()\n",
    "  \n",
    "  for index, row in dataset.iterrows():\n",
    "    refactoring = row.get('refactoring_name')\n",
    "    entity_before = row.get('entity_before_full_name').replace(\" \", \"\")\n",
    "    entity_after = row.get('entity_after_full_name').replace(\" \", \"\")   \n",
    "\n",
    "    if entity_before not in nodes: \n",
    "      nodes[entity_before] = node_number\n",
    "      node_number += 1\n",
    "      \n",
    "    if entity_after not in nodes: \n",
    "      nodes[entity_after] = node_number\n",
    "      node_number += 1     \n",
    "    \n",
    "    #Edges properties\n",
    "    edge = {}\n",
    "    edge['node_before_number'] = nodes.get(entity_before)\n",
    "    edge['node_before_entity'] = entity_before\n",
    "    edge['node_after_number'] = nodes.get(entity_after)\n",
    "    edge['node_after_entity'] = entity_after\n",
    "    edge['edge_number'] = edge_number\n",
    "    edge['refactoring_code'] = dictionary.get(refactoring)\n",
    "\n",
    "    # Add refactoring and commits properties\n",
    "    refactoring_and_commit_fields = datasetconfig.get_refactoring_and_commit_fields()\n",
    "    for field in refactoring_and_commit_fields:\n",
    "      edge[field] = row.get(field)\n",
    "\n",
    "    key = util.get_edge_key(edge.get('node_before_number'), edge.get('node_after_number'))\n",
    "    if key not in edges:\n",
    "      edges[key] = [] #Iniatize new edge\n",
    "    edges[key].append(edge)#Including new refactoring\n",
    "    edge_number += 1  # update edge number\n",
    "\n",
    "  return {'nodes': nodes, 'edges': edges}\n",
    "\n",
    "#----------------------------\n",
    "def create_directed_graph(data):\n",
    "  \n",
    "  DG = nx.DiGraph()\n",
    "  \n",
    "  nodes = data['nodes']\n",
    "  edges = data['edges']\n",
    "  \n",
    "  #Adding nodes\n",
    "  for entity in nodes:\n",
    "    node_index = nodes[entity]\n",
    "    DG.add_node(node_index)\n",
    "   \n",
    "  #Adding edges\n",
    "  for key in edges:\n",
    "    list_edges = edges[key]\n",
    "    for edge in list_edges:#arestas no mesmo sentido.\n",
    "        DG.add_edge(edge['node_before_number'], edge['node_after_number'])\n",
    "    \n",
    "  return {'digraph': DG}\n",
    "\n",
    "#----------------------------\n",
    "def get_edges_by_nodes(node_number_1, node_number_2, graph_data):\n",
    "  \n",
    "  edges = graph_data['edges']\n",
    "  edges_selected = []\n",
    "  \n",
    "  #loooking for edges in the directed graph\n",
    "  edge_key_1 = util.get_edge_key(node_number_1, node_number_2)\n",
    "  edge_key_2 = util.get_edge_key(node_number_2, node_number_1)\n",
    "  \n",
    "  if edge_key_1 in edges:\n",
    "    edges_selected.append(edges[edge_key_1])\n",
    "    \n",
    "  if ((edge_key_2) in edges) and (edge_key_1 != edge_key_2):#para arestas entrando e saindo do mesmo vertice\n",
    "    edges_selected.append(edges[edge_key_2])\n",
    "    \n",
    "  return {'edges': edges_selected}\n",
    "\n",
    "#----------------------------\n",
    "def extract_subgraphs(name_project, digraph, graph_data):\n",
    "  \n",
    "  directed_subgraphs = []\n",
    "  \n",
    "  # undirected digraph\n",
    "  UG = digraph.to_undirected()\n",
    "\n",
    "  # extract subgraphs\n",
    "  #subgraphs = nx.connected_component_subgraphs(UG) \n",
    "  subgraphs = (UG.subgraph(c) for c in nx.connected_components(UG))\n",
    "\n",
    "  #create transactions\n",
    "  for i, subgraph in enumerate(subgraphs):\n",
    "    \n",
    "    directed_subgraph  = {}\n",
    "    directed_subgraph['id_intra_project'] = i\n",
    "    directed_subgraph['name_project'] = name_project\n",
    "    \n",
    "    #add nodes\n",
    "    nodes = []\n",
    "    nodes.extend(subgraph.nodes())\n",
    "    directed_subgraph['nodes'] = nodes\n",
    "    \n",
    "    #add adges\n",
    "    edges = []\n",
    "    \n",
    "    for edge in subgraph.edges():\n",
    "      node_number_1 = edge[0]\n",
    "      node_number_2 = edge[1]\n",
    "      directed_edges = get_edges_by_nodes(node_number_1, node_number_2, graph_data)['edges']\n",
    "      edges.extend(directed_edges)\n",
    "\n",
    "    directed_subgraph['edges'] = edges\n",
    "    \n",
    "    directed_subgraphs.append(directed_subgraph)\n",
    "    \n",
    "  #for i, sg in enumerate(subgraphs):\n",
    "  #    print (\"subgraph {} has {} nodes\".format(i, sg.number_of_nodes()))\n",
    "  #    print (\"\\tNodes:\", sg.nodes(data=True))\n",
    "  #    print (\"\\tEdges:\", sg.edges(data=True))\n",
    "  return {'directed_subgraphs': directed_subgraphs}\n",
    "\n",
    "#----------------------------\n",
    "def split_supgraphs_atomic_and_overtime(subgraphs):\n",
    "  subgraphs_same_commit = []\n",
    "  subgraphs_different_commit = []\n",
    "  for subgraph in subgraphs:\n",
    "    subgraph_contains_different_commits = contains_different_commits(subgraph)\n",
    "    if subgraph_contains_different_commits:\n",
    "      subgraph['label_group'] = 'overtime' \n",
    "      subgraphs_different_commit.append(subgraph)\n",
    "    else:\n",
    "      subgraph['label_group'] = 'atomic' \n",
    "      subgraphs_same_commit.append(subgraph)\n",
    "  return {'subgraphs_same_commit': subgraphs_same_commit, 'subgraphs_different_commit': subgraphs_different_commit}\n",
    "\n",
    "#----------------------------\n",
    "def contains_different_commits(subgraph):\n",
    "  edges = subgraph['edges']\n",
    "  list_commits = []\n",
    "  for edge in edges:\n",
    "    for refactoring in edge:\n",
    "      commit = refactoring['sha1']\n",
    "      if (len(list_commits) > 0) and (commit not in list_commits): #is a new and different commit\n",
    "        return True\n",
    "      list_commits.append(commit)\n",
    "  return False\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def save_graph_to_html(language, config_graphviz):\n",
    "  path = '../../dataset/saner-2020/graphviz/{}'.format(config_graphviz.get('project'))\n",
    "  file_name = '{}_{}_{}.html'.format(config_graphviz.get('label_group'), util.get_name_project_formated(config_graphviz.get('project')), config_graphviz.get('id'))\n",
    "  if os.path.exists('{}/{}'.format(path,file_name)):\n",
    "    print('ERRO: File exists {}/{}'.format(path,file_name))\n",
    "  else:\n",
    "    if not os.path.exists(path):\n",
    "      print('Creating path {}'.format(path))\n",
    "      os.makedirs(path)\n",
    "    print('Creating {}/{}'.format(path,file_name))\n",
    "    with io.open((path + '/' + file_name), 'w', encoding='utf8') as f:\n",
    "      f.write(config_graphviz.get('diggraph').pipe().decode('utf-8'))\n",
    "  return  \n",
    "\n",
    "#-------------------------------------------------------------\n",
    "def create_visualization(language, project_name, subgraphs):\n",
    "    \n",
    "  for subgraph in subgraphs:\n",
    "\n",
    "    diggraph = Digraph(format='svg')\n",
    "    diggraph.attr('node', shape='point', fixedsize='true', width='0.15')\n",
    "    id = subgraph.get('id_intra_project')\n",
    "    label_group = subgraph.get('label_group')\n",
    "\n",
    "    edges = subgraph.get('edges')\n",
    "\n",
    "    for edge in edges:\n",
    "      for refactoring in edge:\n",
    "        refactoring_name = refactoring.get('refactoring_name')\n",
    "        entity_before_full_name = refactoring.get('entity_before_full_name')\n",
    "        entity_after_full_name = refactoring.get('entity_after_full_name')\n",
    "        diggraph.edge(entity_before_full_name, entity_after_full_name, color='red', label=refactoring_name, len='0.1')\n",
    "  \n",
    "    label_text = '\\n\\nProject: {}, ID: {}, Group: {}'.format(project_name, id, label_group)\n",
    "    diggraph.attr(bgcolor='gainsboro', label=label_text, fontcolor='black', rankdir='LR', ratio='auto', pad=\"0.5,0.5\")\n",
    "\n",
    "    config_graphviz = {}\n",
    "    config_graphviz['project'] = project_name\n",
    "    config_graphviz['diggraph'] = diggraph\n",
    "    config_graphviz['id'] = id\n",
    "    config_graphviz['label_group'] = label_group\n",
    "\n",
    "    save_graph_to_html(language, config_graphviz)    \n",
    "\n",
    "  return\n",
    "\n",
    "#----------------------------\n",
    "def find_disconnected_subgraphs():\n",
    "\n",
    "  language = 'java'\n",
    "\n",
    "  for project_name in datasetconfig.get_java_projects():\n",
    "    #Read CSV files\n",
    "    refactorings_file = '../../dataset/saner-2020/refactorings/refactorings_{}_selected_operations.csv'.format(util.get_name_project_formated(project_name))\n",
    "    graph_data = extract_graph_data_from_csv(language, refactorings_file)\n",
    "    \n",
    "    #Create refactoring graphs\n",
    "    digraph = create_directed_graph(graph_data)['digraph']\n",
    "    \n",
    "    #Separate overtime and atomic subgraphs\n",
    "    subgraphs = extract_subgraphs(project_name, digraph, graph_data)['directed_subgraphs']\n",
    "    groups_subgraph = split_supgraphs_atomic_and_overtime(subgraphs)\n",
    "    \n",
    "    #Save results\n",
    "    util.write_json(groups_subgraph.get('subgraphs_same_commit'), '../../dataset/saner-2020/graphs/', 'atomic_subgraphs_{}.json'.format(util.get_name_project_formated(project_name)))\n",
    "    util.write_json(groups_subgraph.get('subgraphs_different_commit'), '../../dataset/saner-2020/graphs/', 'overtime_subgraphs_{}.json'.format(util.get_name_project_formated(project_name)))\n",
    "\n",
    "  return\n",
    "  \n",
    "#----------------------------\n",
    "def create_views():\n",
    "\n",
    "  language = 'java'\n",
    "\n",
    "  for project_name in datasetconfig.get_java_projects():\n",
    "    #over time graphs\n",
    "    json_graphs_different_commit = '../../dataset/saner-2020/graphs/overtime_subgraphs_{}.json'.format(util.get_name_project_formated(project_name))\n",
    "    subgraphs_different_commit = util.read_json(json_graphs_different_commit)\n",
    "    create_visualization(language, project_name, subgraphs_different_commit)\n",
    "\n",
    "    #atomic graphs\n",
    "    json_graphs_same_commit = '../../dataset/saner-2020/graphs/atomic_subgraphs_{}.json'.format(util.get_name_project_formated(project_name))\n",
    "    subgraphs_same_commit = util.read_json(json_graphs_same_commit)\n",
    "    create_visualization(language, project_name, subgraphs_same_commit)\n",
    "\n",
    "  return\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
